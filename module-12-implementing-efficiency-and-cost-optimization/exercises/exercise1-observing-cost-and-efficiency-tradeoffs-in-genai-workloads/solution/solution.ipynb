{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ded844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32040b0",
   "metadata": {},
   "source": [
    "### Review the workload context and usage assumptions provided in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d6e7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workload_name</th>\n",
       "      <th>traffic_pattern</th>\n",
       "      <th>requests_per_day</th>\n",
       "      <th>avg_input_tokens</th>\n",
       "      <th>avg_output_tokens</th>\n",
       "      <th>sla_notes</th>\n",
       "      <th>kg_co2e_per_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simulated GenAI Inference - Customer Support Assistant</td>\n",
       "      <td>steady</td>\n",
       "      <td>250000</td>\n",
       "      <td>650</td>\n",
       "      <td>220</td>\n",
       "      <td>Interactive use case. Prefer p95 latency under ~1200 ms.</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            workload_name traffic_pattern  requests_per_day  avg_input_tokens  \\\n",
       "0  Simulated GenAI Inference - Customer Support Assistant          steady            250000               650   \n",
       "\n",
       "   avg_output_tokens                                                 sla_notes  kg_co2e_per_kwh  \n",
       "0                220  Interactive use case. Prefer p95 latency under ~1200 ms.              0.4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workload_context = {\n",
    "    \"workload_name\": \"Simulated GenAI Inference - Customer Support Assistant\",\n",
    "    \"traffic_pattern\": \"steady\",\n",
    "    \"requests_per_day\": 250_000,\n",
    "    \"avg_input_tokens\": 650,\n",
    "    \"avg_output_tokens\": 220,\n",
    "    \"sla_notes\": \"Interactive use case. Prefer p95 latency under ~1200 ms.\",\n",
    "    \"kg_co2e_per_kwh\": 0.40,\n",
    "}\n",
    "\n",
    "pd.DataFrame([workload_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6bfc7",
   "metadata": {},
   "source": [
    "### Load the baseline inference metrics for the simulated generative AI workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9392dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>baseline_value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p50_latency_ms</td>\n",
       "      <td>420.0</td>\n",
       "      <td>Median end-to-end inference latency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p95_latency_ms</td>\n",
       "      <td>980.0</td>\n",
       "      <td>Tail latency under moderate load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>throughput_requests_per_sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Sustained throughput under steady traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average_memory_gb</td>\n",
       "      <td>22.5</td>\n",
       "      <td>Average GPU memory utilization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cost_per_1k_requests_usd</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Estimated cloud cost based on instance pricing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>estimated_energy_kwh_per_1k_requests</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Rough estimate based on compute utilization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 metric  baseline_value                                           notes\n",
       "0                        p50_latency_ms           420.0             Median end-to-end inference latency\n",
       "1                        p95_latency_ms           980.0                Tail latency under moderate load\n",
       "2           throughput_requests_per_sec            18.0       Sustained throughput under steady traffic\n",
       "3                     average_memory_gb            22.5                  Average GPU memory utilization\n",
       "4              cost_per_1k_requests_usd             7.4  Estimated cloud cost based on instance pricing\n",
       "5  estimated_energy_kwh_per_1k_requests             3.2     Rough estimate based on compute utilization"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_path = Path(\"baseline_inference_metrics.csv\")\n",
    "\n",
    "if not baseline_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"baseline_inference_metrics.csv not found. \"\n",
    "        \"Place it next to this notebook or update baseline_path.\"\n",
    "    )\n",
    "\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d8c06",
   "metadata": {},
   "source": [
    "### Analyze the baseline metrics to identify potential efficiency concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a229de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p95 latency is 980 ms, within the stated interactive target range.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average memory is 22.5 GB; watch GPU sizing and headroom for spikes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimated cost is $7.40 per 1k requests. Scale impact depends on daily volume.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimated energy is 3.20 kWh per 1k requests. Consider energy as a constraint at scale.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         baseline_findings\n",
       "0                       p95 latency is 980 ms, within the stated interactive target range.\n",
       "1                     Average memory is 22.5 GB; watch GPU sizing and headroom for spikes.\n",
       "2           Estimated cost is $7.40 per 1k requests. Scale impact depends on daily volume.\n",
       "3  Estimated energy is 3.20 kWh per 1k requests. Consider energy as a constraint at scale."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull baseline values into a dict for easy downstream calculations.\n",
    "baseline = dict(zip(baseline_df[\"metric\"], baseline_df[\"baseline_value\"]))\n",
    "\n",
    "# A few simple checks based on the workload notes.\n",
    "baseline_findings = []\n",
    "\n",
    "p95 = baseline.get(\"p95_latency_ms\")\n",
    "if p95 is not None:\n",
    "    if p95 > 1200:\n",
    "        baseline_findings.append(f\"p95 latency is {p95:.0f} ms, which may be high for an interactive SLA.\")\n",
    "    else:\n",
    "        baseline_findings.append(f\"p95 latency is {p95:.0f} ms, within the stated interactive target range.\")\n",
    "\n",
    "mem = baseline.get(\"average_memory_gb\")\n",
    "if mem is not None:\n",
    "    if mem >= 24:\n",
    "        baseline_findings.append(f\"Average memory is {mem:.1f} GB, which may force larger (more expensive) GPUs.\")\n",
    "    elif mem >= 16:\n",
    "        baseline_findings.append(f\"Average memory is {mem:.1f} GB; watch GPU sizing and headroom for spikes.\")\n",
    "    else:\n",
    "        baseline_findings.append(f\"Average memory is {mem:.1f} GB, leaving reasonable headroom for common GPU tiers.\")\n",
    "\n",
    "cost = baseline.get(\"cost_per_1k_requests_usd\")\n",
    "if cost is not None:\n",
    "    baseline_findings.append(f\"Estimated cost is ${cost:.2f} per 1k requests. Scale impact depends on daily volume.\")\n",
    "\n",
    "energy = baseline.get(\"estimated_energy_kwh_per_1k_requests\")\n",
    "if energy is not None:\n",
    "    baseline_findings.append(f\"Estimated energy is {energy:.2f} kWh per 1k requests. Consider energy as a constraint at scale.\")\n",
    "\n",
    "pd.DataFrame({\"baseline_findings\": baseline_findings})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b541a8",
   "metadata": {},
   "source": [
    "### Review the simulated optimization scenario and its post-optimization metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cd9cd",
   "metadata": {},
   "source": [
    "#### Optimization Scenario \n",
    "\n",
    "For this exercise, assume the following optimization has already been applied to the generative AI inference system.\n",
    "\n",
    "##### Optimization Applied\n",
    "**INT8 quantization with dynamic batching**\n",
    "\n",
    "##### Description\n",
    "- Reduced-precision (INT8) inference is used to lower memory usage and improve throughput.\n",
    "- Dynamic batching groups multiple requests together to increase hardware utilization under steady traffic.\n",
    "\n",
    "##### Expected Benefits\n",
    "- Lower GPU memory footprint\n",
    "- Higher sustained throughput\n",
    "- Reduced cost per request\n",
    "- Reduced energy consumption per request\n",
    "\n",
    "##### Known Tradeoffs\n",
    "- Median latency may increase slightly due to batching overhead\n",
    "- Output quality impact is expected to be minor but not zero\n",
    "- Occasional formatting drift or subtle tone changes may occur for longer outputs\n",
    "\n",
    "##### Your Task\n",
    "You are **not** asked to design or implement this optimization.\n",
    "\n",
    "Your task is to **evaluate whether this optimization is acceptable** for the workload using the provided performance, cost, and energy metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0057bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reduced precision inference lowers memory and can improve throughput.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batching can increase throughput but may increase median latency under certain traffic patterns.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality impact is assumed to be minimal but not zero (monitor formatting + factuality).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     scenario_notes\n",
       "0                             Reduced precision inference lowers memory and can improve throughput.\n",
       "1  Batching can increase throughput but may increase median latency under certain traffic patterns.\n",
       "2           Quality impact is assumed to be minimal but not zero (monitor formatting + factuality)."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_scenario = {\n",
    "    \"name\": \"INT8 quantization + dynamic batching\",\n",
    "    \"notes\": [\n",
    "        \"Reduced precision inference lowers memory and can improve throughput.\",\n",
    "        \"Batching can increase throughput but may increase median latency under certain traffic patterns.\",\n",
    "        \"Quality impact is assumed to be minimal but not zero (monitor formatting + factuality).\",\n",
    "    ],\n",
    "    \"quality_impact_note\": \"Minor: occasional slight tone shift and rare formatting drift under long outputs.\",\n",
    "}\n",
    "\n",
    "pd.DataFrame({\"scenario_notes\": optimization_scenario[\"notes\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba56c9d",
   "metadata": {},
   "source": [
    "### Construct a comparison table that summarizes baseline and optimized metrics side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170dd740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>baseline_value</th>\n",
       "      <th>notes</th>\n",
       "      <th>optimized_value</th>\n",
       "      <th>delta</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p50_latency_ms</td>\n",
       "      <td>420.0</td>\n",
       "      <td>Median end-to-end inference latency</td>\n",
       "      <td>460.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p95_latency_ms</td>\n",
       "      <td>980.0</td>\n",
       "      <td>Tail latency under moderate load</td>\n",
       "      <td>820.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-16.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>throughput_requests_per_sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Sustained throughput under steady traffic</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average_memory_gb</td>\n",
       "      <td>22.5</td>\n",
       "      <td>Average GPU memory utilization</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>-36.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cost_per_1k_requests_usd</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Estimated cloud cost based on instance pricing</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-37.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>estimated_energy_kwh_per_1k_requests</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Rough estimate based on compute utilization</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-34.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 metric  baseline_value                                           notes  \\\n",
       "0                        p50_latency_ms           420.0             Median end-to-end inference latency   \n",
       "1                        p95_latency_ms           980.0                Tail latency under moderate load   \n",
       "2           throughput_requests_per_sec            18.0       Sustained throughput under steady traffic   \n",
       "3                     average_memory_gb            22.5                  Average GPU memory utilization   \n",
       "4              cost_per_1k_requests_usd             7.4  Estimated cloud cost based on instance pricing   \n",
       "5  estimated_energy_kwh_per_1k_requests             3.2     Rough estimate based on compute utilization   \n",
       "\n",
       "   optimized_value  delta  pct_change  \n",
       "0            460.0   40.0    9.523810  \n",
       "1            820.0 -160.0  -16.326531  \n",
       "2             32.0   14.0   77.777778  \n",
       "3             14.2   -8.3  -36.888889  \n",
       "4              4.6   -2.8  -37.837838  \n",
       "5              2.1   -1.1  -34.375000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulated optimized metrics aligned to the baseline metric list\n",
    "optimized_metrics = {\n",
    "    \"p50_latency_ms\": 460,                         # slight increase due to batching overhead\n",
    "    \"p95_latency_ms\": 820,                         # improved tail latency via better throughput + lower contention\n",
    "    \"throughput_requests_per_sec\": 32,             # improved\n",
    "    \"average_memory_gb\": 14.2,                     # reduced memory footprint\n",
    "    \"cost_per_1k_requests_usd\": 4.60,              # lower cost\n",
    "    \"estimated_energy_kwh_per_1k_requests\": 2.1,   # lower energy\n",
    "}\n",
    "\n",
    "optimized_df = pd.DataFrame({\n",
    "    \"metric\": list(optimized_metrics.keys()),\n",
    "    \"optimized_value\": list(optimized_metrics.values())\n",
    "})\n",
    "\n",
    "comparison = baseline_df.merge(optimized_df, on=\"metric\", how=\"left\")\n",
    "\n",
    "# Add deltas and percent deltas\n",
    "comparison[\"delta\"] = comparison[\"optimized_value\"] - comparison[\"baseline_value\"]\n",
    "comparison[\"pct_change\"] = np.where(\n",
    "    comparison[\"baseline_value\"] != 0,\n",
    "    (comparison[\"delta\"] / comparison[\"baseline_value\"]) * 100,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade38d79",
   "metadata": {},
   "source": [
    "### Calculate and summarize the differences between baseline and optimized metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a2b14ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>requests_per_day</th>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_cost_per_day_usd</th>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_cost_per_day_usd</th>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_cost_savings_usd</th>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_energy_kwh_per_day</th>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_energy_kwh_per_day</th>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_energy_savings_kwh</th>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assumed_kg_co2e_per_kwh</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_co2e_kg_per_day</th>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_co2e_kg_per_day</th>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_co2e_savings_kg</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 value\n",
       "requests_per_day              250000.0\n",
       "baseline_cost_per_day_usd       1850.0\n",
       "optimized_cost_per_day_usd      1150.0\n",
       "daily_cost_savings_usd           700.0\n",
       "baseline_energy_kwh_per_day      800.0\n",
       "optimized_energy_kwh_per_day     525.0\n",
       "daily_energy_savings_kwh         275.0\n",
       "assumed_kg_co2e_per_kwh            0.4\n",
       "baseline_co2e_kg_per_day         320.0\n",
       "optimized_co2e_kg_per_day        210.0\n",
       "daily_co2e_savings_kg            110.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests_per_day = workload_context[\"requests_per_day\"]\n",
    "\n",
    "# Pull per-1k request cost/energy and scale them\n",
    "baseline_cost_per_day = (baseline[\"cost_per_1k_requests_usd\"] * requests_per_day) / 1000\n",
    "optimized_cost_per_day = (optimized_metrics[\"cost_per_1k_requests_usd\"] * requests_per_day) / 1000\n",
    "\n",
    "baseline_energy_per_day = (baseline[\"estimated_energy_kwh_per_1k_requests\"] * requests_per_day) / 1000\n",
    "optimized_energy_per_day = (optimized_metrics[\"estimated_energy_kwh_per_1k_requests\"] * requests_per_day) / 1000\n",
    "\n",
    "# Optional CO2e estimate (assumption-based)\n",
    "kg_co2e_per_kwh = workload_context.get(\"kg_co2e_per_kwh\", None)\n",
    "baseline_co2e_kg_per_day = baseline_energy_per_day * kg_co2e_per_kwh if kg_co2e_per_kwh is not None else None\n",
    "optimized_co2e_kg_per_day = optimized_energy_per_day * kg_co2e_per_kwh if kg_co2e_per_kwh is not None else None\n",
    "\n",
    "scale_summary = {\n",
    "    \"requests_per_day\": requests_per_day,\n",
    "    \"baseline_cost_per_day_usd\": baseline_cost_per_day,\n",
    "    \"optimized_cost_per_day_usd\": optimized_cost_per_day,\n",
    "    \"daily_cost_savings_usd\": baseline_cost_per_day - optimized_cost_per_day,\n",
    "    \"baseline_energy_kwh_per_day\": baseline_energy_per_day,\n",
    "    \"optimized_energy_kwh_per_day\": optimized_energy_per_day,\n",
    "    \"daily_energy_savings_kwh\": baseline_energy_per_day - optimized_energy_per_day,\n",
    "}\n",
    "\n",
    "if baseline_co2e_kg_per_day is not None:\n",
    "    scale_summary.update({\n",
    "        \"assumed_kg_co2e_per_kwh\": kg_co2e_per_kwh,\n",
    "        \"baseline_co2e_kg_per_day\": baseline_co2e_kg_per_day,\n",
    "        \"optimized_co2e_kg_per_day\": optimized_co2e_kg_per_day,\n",
    "        \"daily_co2e_savings_kg\": baseline_co2e_kg_per_day - optimized_co2e_kg_per_day,\n",
    "    })\n",
    "\n",
    "pd.DataFrame([scale_summary]).T.rename(columns={0: \"value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c46e43",
   "metadata": {},
   "source": [
    "### Evaluate the tradeoffs introduced by the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3835129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>what_changed</th>\n",
       "      <th>interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latency</td>\n",
       "      <td>p50: 420.0 -&gt; 460 ms, p95: 980.0 -&gt; 820 ms</td>\n",
       "      <td>Median latency slightly increased (batching overhead), but tail latency improved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Throughput</td>\n",
       "      <td>18.0 -&gt; 32 req/s</td>\n",
       "      <td>Higher throughput reduces queueing risk and can stabilize tail latency under load.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memory</td>\n",
       "      <td>22.5 -&gt; 14.2 GB</td>\n",
       "      <td>Lower memory enables smaller instances or more headroom, improving cost flexibility.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Output Quality</td>\n",
       "      <td>Minor: occasional slight tone shift and rare formatting drift under long outputs.</td>\n",
       "      <td>Treat as a monitoring requirement. Add regression tests for tone, formatting, and factuality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             area                                                                       what_changed  \\\n",
       "0         Latency                                         p50: 420.0 -> 460 ms, p95: 980.0 -> 820 ms   \n",
       "1      Throughput                                                                   18.0 -> 32 req/s   \n",
       "2          Memory                                                                    22.5 -> 14.2 GB   \n",
       "3  Output Quality  Minor: occasional slight tone shift and rare formatting drift under long outputs.   \n",
       "\n",
       "                                                                                  interpretation  \n",
       "0              Median latency slightly increased (batching overhead), but tail latency improved.  \n",
       "1             Higher throughput reduces queueing risk and can stabilize tail latency under load.  \n",
       "2           Lower memory enables smaller instances or more headroom, improving cost flexibility.  \n",
       "3  Treat as a monitoring requirement. Add regression tests for tone, formatting, and factuality.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeoffs = []\n",
    "\n",
    "# Latency tradeoff (p50 may increase; p95 may improve)\n",
    "tradeoffs.append({\n",
    "    \"area\": \"Latency\",\n",
    "    \"what_changed\": f\"p50: {baseline['p50_latency_ms']} -> {optimized_metrics['p50_latency_ms']} ms, \"\n",
    "                    f\"p95: {baseline['p95_latency_ms']} -> {optimized_metrics['p95_latency_ms']} ms\",\n",
    "    \"interpretation\": \"Median latency slightly increased (batching overhead), but tail latency improved.\"\n",
    "})\n",
    "\n",
    "# Throughput\n",
    "tradeoffs.append({\n",
    "    \"area\": \"Throughput\",\n",
    "    \"what_changed\": f\"{baseline['throughput_requests_per_sec']} -> {optimized_metrics['throughput_requests_per_sec']} req/s\",\n",
    "    \"interpretation\": \"Higher throughput reduces queueing risk and can stabilize tail latency under load.\"\n",
    "})\n",
    "\n",
    "# Memory\n",
    "tradeoffs.append({\n",
    "    \"area\": \"Memory\",\n",
    "    \"what_changed\": f\"{baseline['average_memory_gb']} -> {optimized_metrics['average_memory_gb']} GB\",\n",
    "    \"interpretation\": \"Lower memory enables smaller instances or more headroom, improving cost flexibility.\"\n",
    "})\n",
    "\n",
    "# Quality / flexibility (scenario-based note)\n",
    "tradeoffs.append({\n",
    "    \"area\": \"Output Quality\",\n",
    "    \"what_changed\": optimization_scenario[\"quality_impact_note\"],\n",
    "    \"interpretation\": \"Treat as a monitoring requirement. Add regression tests for tone, formatting, and factuality.\"\n",
    "})\n",
    "\n",
    "pd.DataFrame(tradeoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a0497",
   "metadata": {},
   "source": [
    "### Short analysis and clear recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd098981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "- Cost: $7.40 -> $4.60 per 1k requests.\n",
      "- Energy: 3.20 -> 2.10 kWh per 1k requests.\n",
      "- Throughput: 18 -> 32 req/s.\n",
      "- Latency: p50 increased slightly (420 -> 460 ms) while p95 improved\n",
      "  (980 -> 820 ms).\n",
      "\n",
      "Assessment\n",
      "The optimization appears acceptable for this interactive workload because tail latency improves and throughput increases materially,\n",
      "while cost and energy per 1k requests drop significantly. The primary tradeoff is a modest p50 latency increase and a potential minor\n",
      "quality impact due to reduced precision and batching. If adopted, pair the change with lightweight quality regression checks and\n",
      "monitor p50 latency under real traffic to ensure batching does not degrade perceived responsiveness.\n"
     ]
    }
   ],
   "source": [
    "analysis = f\"\"\"\n",
    "Summary\n",
    "- Cost: ${baseline['cost_per_1k_requests_usd']:.2f} -> ${optimized_metrics['cost_per_1k_requests_usd']:.2f} per 1k requests.\n",
    "- Energy: {baseline['estimated_energy_kwh_per_1k_requests']:.2f} -> {optimized_metrics['estimated_energy_kwh_per_1k_requests']:.2f} kWh per 1k requests.\n",
    "- Throughput: {baseline['throughput_requests_per_sec']:.0f} -> {optimized_metrics['throughput_requests_per_sec']:.0f} req/s.\n",
    "- Latency: p50 increased slightly ({baseline['p50_latency_ms']:.0f} -> {optimized_metrics['p50_latency_ms']:.0f} ms) while p95 improved\n",
    "  ({baseline['p95_latency_ms']:.0f} -> {optimized_metrics['p95_latency_ms']:.0f} ms).\n",
    "\n",
    "Assessment\n",
    "The optimization appears acceptable for this interactive workload because tail latency improves and throughput increases materially,\n",
    "while cost and energy per 1k requests drop significantly. The primary tradeoff is a modest p50 latency increase and a potential minor\n",
    "quality impact due to reduced precision and batching. If adopted, pair the change with lightweight quality regression checks and\n",
    "monitor p50 latency under real traffic to ensure batching does not degrade perceived responsiveness.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "969cb78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>why</th>\n",
       "      <th>guardrails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adopt with guardrails</td>\n",
       "      <td>Tail latency, throughput, memory, cost, and energy improved materially; risks are manageable with monitoring and tests.</td>\n",
       "      <td>Run A/B rollout with real traffic and monitor p50/p95 latency and error rates.; Add automated quality regression checks for formatting, tone stability, and factuality.; Set batching limits to avoid excessive median latency under low traffic.; Revisit cost/energy estimates monthly using actual infrastructure billing and utilization.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                decision  \\\n",
       "0  Adopt with guardrails   \n",
       "\n",
       "                                                                                                                       why  \\\n",
       "0  Tail latency, throughput, memory, cost, and energy improved materially; risks are manageable with monitoring and tests.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                      guardrails  \n",
       "0  Run A/B rollout with real traffic and monitor p50/p95 latency and error rates.; Add automated quality regression checks for formatting, tone stability, and factuality.; Set batching limits to avoid excessive median latency under low traffic.; Revisit cost/energy estimates monthly using actual infrastructure billing and utilization.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation = {\n",
    "    \"decision\": \"Adopt with guardrails\",\n",
    "    \"guardrails\": [\n",
    "        \"Run A/B rollout with real traffic and monitor p50/p95 latency and error rates.\",\n",
    "        \"Add automated quality regression checks for formatting, tone stability, and factuality.\",\n",
    "        \"Set batching limits to avoid excessive median latency under low traffic.\",\n",
    "        \"Revisit cost/energy estimates monthly using actual infrastructure billing and utilization.\",\n",
    "    ],\n",
    "    \"why\": \"Tail latency, throughput, memory, cost, and energy improved materially; risks are manageable with monitoring and tests.\"\n",
    "}\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"decision\": [recommendation[\"decision\"]],\n",
    "    \"why\": [recommendation[\"why\"]],\n",
    "    \"guardrails\": [\"; \".join(recommendation[\"guardrails\"])]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
