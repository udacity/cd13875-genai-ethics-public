{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4ac89",
   "metadata": {},
   "source": [
    "### Load the provided dataset containing simulated generative AI outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"simulated_genai_outputs.jsonl\")\n",
    "\n",
    "# TODO: Load the JSONL file into a list of Python dicts called `records`.\n",
    "# - Each line is a JSON object\n",
    "# - Use json.loads(...)\n",
    "# - Skip blank lines safely\n",
    "records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc1a5b",
   "metadata": {},
   "source": [
    "### Review a sample of the outputs to understand the scenarios and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display a random sample of 5 rows with these columns:\n",
    "# - output_id\n",
    "# - timestamp\n",
    "# - text\n",
    "# Hint: df.sample(...)[[...]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cba1",
   "metadata": {},
   "source": [
    "### Establish a baseline leakage assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b00716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex library of common leakage patterns\n",
    "PATTERNS = {\n",
    "    \"email\": re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"),\n",
    "    \"phone_us\": re.compile(r\"\\b(?:\\+1[-.\\s]?)?(?:\\(\\d{3}\\)|\\d{3})[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"),\n",
    "    \"ssn_us\": re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"),\n",
    "    \"credit_card_like\": re.compile(r\"\\b(?:\\d[ -]*?){13,19}\\b\"),\n",
    "    \"date_mmddyyyy\": re.compile(r\"\\b(0?[1-9]|1[0-2])[/-](0?[1-9]|[12]\\d|3[01])[/-](19|20)\\d{2}\\b\"),\n",
    "    \"employee_id_like\": re.compile(r\"\\bEMP-\\d{4,}\\b\", re.IGNORECASE),\n",
    "    \"case_id_like\": re.compile(r\"\\bCASE-\\d{4}-\\d{2}-\\d{3,}\\b\", re.IGNORECASE),\n",
    "    \"order_id_like\": re.compile(r\"\\b#[A-Z0-9-]{5,}\\b\"),\n",
    "    \"internal_url\": re.compile(r\"\\bhttps?://[A-Za-z0-9.-]*\\b(?:internal|corp|local)\\b[A-Za-z0-9./+_-]*\\b\", re.IGNORECASE),\n",
    "    \"hostname_internal\": re.compile(r\"\\b[A-Za-z0-9-]+\\.(?:internal|local|corp)\\.[A-Za-z]{2,}\\b\", re.IGNORECASE),\n",
    "    \"api_key_like\": re.compile(r\"\\b(?:sk-[A-Za-z0-9]{8,}|AKIA[0-9A-Z]{16})\\b\"),\n",
    "    \"password_like\": re.compile(r\"\\b(?:temp(?:orary)?\\s*password\\s*:\\s*\\S+|password\\s*:\\s*\\S+)\\b\", re.IGNORECASE),\n",
    "}\n",
    "\n",
    "# TODO Implement a function `detect_signals(text, patterns)` that:\n",
    "# - Iterates over pattern dict items\n",
    "# - Counts matches for each pattern\n",
    "# - Adds a \"total_signals\" field equal to the sum of all category counts\n",
    "#\n",
    "# def detect_signals(text: str, patterns: dict) -> dict:\n",
    "#     ...\n",
    "\n",
    "\n",
    "# TODO Apply detect_signals to df[\"text\"] and expand into columns\n",
    "# - signals = df[\"text\"].apply(...).apply(pd.Series)\n",
    "# - df_base = pd.concat([...], axis=1)\n",
    "# df_base = ...\n",
    "\n",
    "\n",
    "# TODO Display a baseline preview table with:\n",
    "# [\"output_id\", \"total_signals\"] + list(PATTERNS.keys())\n",
    "# Hint: df_base[[...]].head()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Create a baseline summary table\n",
    "# ------------------------------------------------------------\n",
    "# TODO Build `summary_base` that:\n",
    "# - keeps output_id, timestamp, total_signals, and each pattern column\n",
    "# - sorts by total_signals descending, then output_id ascending\n",
    "# - resets index\n",
    "# summary_base = ...\n",
    "\n",
    "\n",
    "# TODO: Display summary_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ef47c",
   "metadata": {},
   "source": [
    "### Document your baseline findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_THRESHOLD = 1\n",
    "\n",
    "risky = summary_base[summary_base[\"total_signals\"] >= RISK_THRESHOLD]\n",
    "clean = summary_base[summary_base[\"total_signals\"] == 0]\n",
    "\n",
    "print(f\"Total outputs: {len(summary_base)}\")\n",
    "print(f\"Risky outputs (>= {RISK_THRESHOLD} signal): {len(risky)}\")\n",
    "print(f\"Clean outputs (0 signals): {len(clean)}\\n\")\n",
    "\n",
    "# Which categories appear most\n",
    "category_totals = summary_base[list(PATTERNS.keys())].sum().sort_values(ascending=False)\n",
    "category_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3234d5",
   "metadata": {},
   "source": [
    "### Apply lightweight privacy defenses to reduce leakage risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-based redaction\n",
    "REDACTIONS = {\n",
    "    \"email\": \"[REDACTED_EMAIL]\",\n",
    "    \"phone_us\": \"[REDACTED_PHONE]\",\n",
    "    \"ssn_us\": \"[REDACTED_SSN]\",\n",
    "    \"credit_card_like\": \"[REDACTED_CARD]\",\n",
    "    \"date_mmddyyyy\": \"[REDACTED_DATE]\",\n",
    "    \"employee_id_like\": \"[REDACTED_EMPLOYEE_ID]\",\n",
    "    \"case_id_like\": \"[REDACTED_CASE_ID]\",\n",
    "    \"order_id_like\": \"[REDACTED_ORDER_ID]\",\n",
    "    \"internal_url\": \"[REDACTED_INTERNAL_URL]\",\n",
    "    \"hostname_internal\": \"[REDACTED_INTERNAL_HOST]\",\n",
    "    \"api_key_like\": \"[REDACTED_SECRET]\",\n",
    "    \"password_like\": \"[REDACTED_PASSWORD]\",\n",
    "}\n",
    "\n",
    "def redact_text(text: str, patterns: dict, replacements: dict) -> str:\n",
    "    redacted = text or \"\"\n",
    "    # Apply more specific patterns first to reduce accidental over-redaction\n",
    "    for name, rx in patterns.items():\n",
    "        token = replacements.get(name, \"[REDACTED]\")\n",
    "        redacted = rx.sub(token, redacted)\n",
    "    return redacted\n",
    "\n",
    "df_mitigated = df_base.copy()\n",
    "df_mitigated[\"text_mitigated\"] = df_mitigated[\"text\"].apply(lambda t: redact_text(t, PATTERNS, REDACTIONS))\n",
    "df_mitigated[[\"output_id\", \"text\", \"text_mitigated\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f51ee",
   "metadata": {},
   "source": [
    "### Re-evaluate the same outputs after defenses are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_signals = df_mitigated[\"text_mitigated\"].apply(lambda t: detect_signals(t, PATTERNS)).apply(pd.Series)\n",
    "df_after = pd.concat([df_mitigated, after_signals.add_prefix(\"after_\")], axis=1)\n",
    "\n",
    "compare_cols = (\n",
    "    [\"output_id\", \"total_signals\", \"after_total_signals\"]\n",
    "    + [k for k in PATTERNS.keys()]\n",
    "    + [f\"after_{k}\" for k in PATTERNS.keys()]\n",
    ")\n",
    "\n",
    "comparison = df_after[compare_cols].copy()\n",
    "comparison[\"delta_total\"] = comparison[\"after_total_signals\"] - comparison[\"total_signals\"]\n",
    "\n",
    "comparison.sort_values([\"delta_total\", \"output_id\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c190b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_total = int(df_after[\"total_signals\"].sum())\n",
    "after_total = int(df_after[\"after_total_signals\"].sum())\n",
    "\n",
    "print(f\"Total signals BEFORE: {before_total}\")\n",
    "print(f\"Total signals AFTER:  {after_total}\")\n",
    "print(f\"Net change (AFTER - BEFORE): {after_total - before_total}\")\n",
    "\n",
    "by_category = pd.DataFrame({\n",
    "    \"before\": df_after[list(PATTERNS.keys())].sum(),\n",
    "    \"after\": df_after[[f\"after_{k}\" for k in PATTERNS.keys()]].sum().rename(lambda s: s.replace(\"after_\", \"\")),\n",
    "})\n",
    "by_category[\"delta\"] = by_category[\"after\"] - by_category[\"before\"]\n",
    "by_category.sort_values(\"delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87778aad",
   "metadata": {},
   "source": [
    "### Assess defense effectiveness and document results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_effectiveness(before: int, after: int) -> str:\n",
    "    if before == 0 and after == 0:\n",
    "        return \"N/A (no signals)\"\n",
    "    if before > 0 and after == 0:\n",
    "        return \"Effective\"\n",
    "    if before > 0 and 0 < after < before:\n",
    "        return \"Partially effective\"\n",
    "    if before > 0 and after >= before:\n",
    "        return \"Ineffective\"\n",
    "    # edge case: before==0, after>0 (shouldn't happen, but guard)\n",
    "    return \"Regression\"\n",
    "\n",
    "effectiveness = []\n",
    "for k in PATTERNS.keys():\n",
    "    b = int(by_category.loc[k, \"before\"])\n",
    "    a = int(by_category.loc[k, \"after\"])\n",
    "    effectiveness.append({\n",
    "        \"category\": k,\n",
    "        \"before\": b,\n",
    "        \"after\": a,\n",
    "        \"effectiveness\": classify_effectiveness(b, a),\n",
    "    })\n",
    "\n",
    "effectiveness_df = pd.DataFrame(effectiveness).sort_values([\"effectiveness\", \"category\"])\n",
    "effectiveness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb76538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a couple of the highest-risk examples\n",
    "top = df_after.sort_values(\"total_signals\", ascending=False).head(3)\n",
    "\n",
    "for _, row in top.iterrows():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"OUTPUT_ID: {row['output_id']} | timestamp: {row['timestamp']} | baseline signals: {int(row['total_signals'])}\")\n",
    "    print(\"-\"*100)\n",
    "    print(\"BEFORE:\\n\")\n",
    "    print(row[\"text\"])\n",
    "    print(\"\\nAFTER (mitigated):\\n\")\n",
    "    print(row[\"text_mitigated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2686fa",
   "metadata": {},
   "source": [
    "### Design a structured incident response protocol and write-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Incident response protocol for GenAI leakage\n",
    "# ------------------------------------------------------------\n",
    "# TODO: Create a structured incident response protocol.\n",
    "# Represent it as a Python dict named INCIDENT_RESPONSE_PROTOCOL that includes:\n",
    "# - detection_and_escalation (signals, severity tiers, escalation criteria, owners)\n",
    "# - containment (immediate actions, short-term actions)\n",
    "# - notification_and_documentation (notify list, record list)\n",
    "# - post_incident_review (root cause, remediation, follow-up)\n",
    "#\n",
    "# INCIDENT_RESPONSE_PROTOCOL = { ... }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9812e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Instruction Step 10: Security-focused write-up\n",
    "# ------------------------------------------------------------\n",
    "# TODO: Create 4-6 bullet points for:\n",
    "# - technical controls you implemented\n",
    "# - procedural safeguards you designed\n",
    "#\n",
    "# Then print a markdown-friendly summary that can be pasted into a markdown cell.\n",
    "#\n",
    "# Hint: Build lists, then join them into a formatted string."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
